{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 672,
     "status": "ok",
     "timestamp": 1682480365041,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "3RBuxsyWhY3j"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch 사용.\n",
    "nn으로 줄임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1682480033841,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "H-4zf83ynk4c",
    "outputId": "3fc80ba4-7c37-4fad-d8ff-e2108bba44a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim = 2\n",
      "torch.Size([3, 3])\n",
      "tensor([[1, 1, 0],\n",
      "        [4, 2, 1],\n",
      "        [0, 2, 1]])\n",
      "ndim = 1\n",
      "torch.Size([9])\n",
      "tensor([1, 1, 0, 4, 2, 1, 0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,1,0],[4,2,1],[0,2,1]])\n",
    "print('ndim =', x.ndim)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "y = torch.flatten(x)\n",
    "print('ndim =', y.ndim)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x.ndim : x텐서의 차원 수 반환하는 속성\n",
    "x.shape: 텐서의 각 차원 크기 반환하는 속성. \n",
    "x: 텐서 전체 출력\n",
    "torch.flatten: 1차원으로 평탄화\n",
    "y: 평탄화된 x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1682480218046,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "ujghkpDin181",
    "outputId": "fb8a23e9-b22a-457c-f9b5-2f24a9b0bdcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim = 3\n",
      "torch.Size([1, 3, 3])\n",
      "tensor([[[1, 1, 0],\n",
      "         [4, 2, 1],\n",
      "         [0, 2, 1]]])\n",
      "ndim = 2\n",
      "torch.Size([1, 9])\n",
      "tensor([[1, 1, 0, 4, 2, 1, 0, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[[1,1,0],[4,2,1],[0,2,1]]])\n",
    "print('ndim =', x.ndim)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "y = torch.flatten(x,1)\n",
    "print('ndim =', y.ndim)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x.ndim : x텐서의 차원 수 반환하는 속성; 차원수 3\n",
    "x.shape: 텐서의 각 차원 크기 반환하는 속성. \n",
    "x: 텐서 전체 출력\n",
    "torch.flatten: 2차원으로 평탄화, 단 첫 번째는 놔두고 두 번째 차원부터 끝까지.\n",
    "y: 평탄화된 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1682480367477,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "oZ44UOmqooVj",
    "outputId": "ed9ad91a-97f3-40cf-f787-f76ce1ab04a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim = 3\n",
      "torch.Size([1, 3, 3])\n",
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n",
      "ndim = 2\n",
      "torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[[1,1,0],[4,2,1],[0,2,1]]])\n",
    "print('ndim =', x.ndim)\n",
    "print(x.shape)\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten()\n",
    ")\n",
    "print(model)\n",
    "y = model(x)\n",
    "print('ndim =', y.ndim)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Sequential() : 레이어 순차적으로 쌓는 컨테이너\n",
    "-> 이 코드에선 Flatten 레이어 하나만 통과.\n",
    " - start_dim=1: 평탄화 시작 차원(1번 차원부터.0번 차원(배치)는 유지.)\n",
    " - end_dim=-1: 평탄화 끝낼 차원(마지막 차원)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEto9QeOpTW6"
   },
   "source": [
    "CNN 모델 파이토치 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1682480638604,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "QEDzf9SjpM19",
    "outputId": "8e1c8e8f-c4e5-48b0-e9d0-ecae24dac6f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "numpy, matplotlib, torch, torchvision 등 딥러닝 데이터 시각화에 필요한 라이브러리 임포트.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "-> cuda(GPU) 설치됐다면 cuda, 아니면 CPU.\n",
    "\n",
    "print('Device:', device)\n",
    "-> 현재 device는 CPU.\n",
    "\n",
    "이렇게 지정한 device는 모델이나 데이터를 해당 device로 옮길 때 사용.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1585,
     "status": "ok",
     "timestamp": 1682481004411,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "xysdVqqlp7J6",
    "outputId": "7910b3f7-e2a7-4630-a567-a7dc15573a94"
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='MNIST_data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=None)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='MNIST_data', \n",
    "                                        train=False, \n",
    "                                        download=True, \n",
    "                                        transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='MNIST_data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=None)\n",
    "                                        \n",
    "- root='MNIST_data': 데이터셋 저장될 경로 지정. \n",
    "- train=True: 학습용 데이터셋(훈련데이터) 불러오기.\n",
    "- download=True: 해당 경로에 데이터 없으면 자동으로 다운로드.\n",
    "- transform=None: 데이터에 적용할 변환(transform)을 지정. None이면 변환 없이 원본 데이터 사용.\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='MNIST_data', \n",
    "                                        train=False, \n",
    "                                        download=True, \n",
    "                                        transform=None)\n",
    "\n",
    "- root='MNIST_data': 데이터셋 저장될 경로 지정. \n",
    "- train=False: 테스용 데이터셋(검증 데이터) 불러오기.\n",
    "- download=True: 해당 경로에 데이터 없으면 자동으로 다운로드.\n",
    "- transform=None: 데이터에 적용할 변환(transform)을 지정. None이면 변환 없이 원본 데이터 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1682481033780,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "1cOvIJFvrra3",
    "outputId": "6fddaed9-958e-4dfe-ad37-bc49b7fc93ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: MNIST_data\n",
      "    Split: Train\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: MNIST_data\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터셋은 손글씨 숫자 이미지(0~9)와 해당 숫자 레이블로 구성되어 있으며, 딥러닝 모델 학습에 자주 사용되는 대표적인 이미지 분류 데이터셋.\n",
    "\n",
    "학습용 : 60000개\n",
    "테스트용 : 10000개\n",
    "로 데이터분할. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1682481073926,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "qVCO8GSFry4D",
    "outputId": "caac2acd-b127-4a25-de5d-bab66b7e2a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "<class 'tuple'>\n",
      "(<PIL.Image.Image image mode=L size=28x28 at 0x1DFC6CA2C00>, 5)\n",
      "(<PIL.Image.Image image mode=L size=28x28 at 0x1DFC2B05880>, 7)\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset[0]))\n",
    "print(type(test_dataset[0]))\n",
    "print(train_dataset[0])\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(type(train_dataset[0]))\n",
    "print(type(test_dataset[0]))\n",
    "학습과 테스트 데이터셋에서 첫 번째 샘플 가져와 타입인 튜플 출력.\n",
    "print(train_dataset[0])\n",
    "print(test_dataset[0])\n",
    "각 튜플의 첫 번째 원소는 PIL 이미지 객체(mode='L', 즉 흑백 28*28 이미지)\n",
    "두 번째 원소는 정수형 레이블(0~9의 숫자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1682481854200,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "6mUMyrg0r8rd",
    "outputId": "43852ee7-5c79-4ce4-9179-c5d9b4bb5419"
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_dataset[0][0], cmap='gray')\n",
    "plt.title('%i' % train_dataset[0][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.imshow(train_dataset[0][0], cmap='gray')\n",
    "\n",
    "- train_dataset은 (이미지, 레이블) 형태의 튜플.\n",
    "- 따라서 train_dataset[0][0]은 첫 번째 train_dataset의 PIL.Image.Image 객체.\n",
    "- cmap = 'gray' 이미지를 흑백으로 시각화.\n",
    "  \n",
    "plt.title('%i' % train_dataset[0][1])\n",
    "\n",
    "- 제목을 해당 데이터의 튜플 속 레이블로.\n",
    "  \n",
    "plt.show()\n",
    "- 화면 출력. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1682481895241,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "Tn-n5W6pu67t",
    "outputId": "91731c5d-a338-4c8b-e03c-971493065676"
   },
   "outputs": [],
   "source": [
    "#numpy 배열로 변환\n",
    "print(type(train_dataset[0][0]))\n",
    "image = np.array(train_dataset[0][0])\n",
    "print(type(image))\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(type(train_dataset[0][0])) \n",
    "- train_dataset[0][0]은 첫 번째 train_dataset의 PIL.Image.Image 객체이므로\n",
    " class 'PIL.Image.Image' 출력.\n",
    " \n",
    "image = np.array(train_dataset[0][0])\n",
    "- PIL 이미지를 numpy 배열로 변환.\n",
    "\n",
    "print(type(image))\n",
    "- <class 'numpy.ndarray'> numpy 배열로 변환됐음을 확인.\n",
    "  \n",
    "print(image)\n",
    "- 28x28 크기의 2차원 numpy 배열이 출력. 각 원소는 픽셀의 밝기(0~255) 값."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1184,
     "status": "ok",
     "timestamp": 1682482003834,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "R2l0Br_kvFGO",
    "outputId": "455c8633-a312-428d-d65a-cd08c71b4212"
   },
   "outputs": [],
   "source": [
    "#MNIST 데이터를 텐서로 변환\n",
    "transform = transforms.ToTensor()     \n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='MNIST_data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='MNIST_data', \n",
    "                                        train=False, \n",
    "                                        download=True, \n",
    "                                        transform=transform)\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform = transforms.ToTensor()\n",
    "- 이미지를 0~1 실수값의 torch.FloatTensor로 변환.\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "- 데이터셋 객체 정보 출력.\n",
    "\n",
    "- root='MNIST_data': 데이터셋 저장될 경로 지정. \n",
    "- train=True: 학습용 데이터셋(훈련데이터) 불러오기.\n",
    "- train=False: 테스용 데이터셋(검증 데이터) 불러오기.\n",
    "- download=True: 해당 경로에 데이터 없으면 자동으로 다운로드.\n",
    "- transform=transform: 데이터에 적용할 변환(transform)을 지정. PIL 이미지 -> torch.Tensor로 자동 변환해서 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1682483758609,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "vb3ma5ce2L2p"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "#    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray' )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<plt.imshow() 구현>\n",
    "\n",
    "npimg = img.numpy()\n",
    "- PIL이미지인 img -> numpy배열인 npimg로 변환.\n",
    "\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray' )\n",
    "- PyTorch 이미지 텐서는 (채널, 높이, 너비)순.\n",
    "- matplotlib는 (높이, 너비, 채널)순서를 기대하므로, np.transpose로 (0,1,2)에서 (1,2,0)으로 차원 순서 바꿔주기.\n",
    "- cmap='gray'는 흑백 이미지를 그레이스케일로 표시.\n",
    "\n",
    "plt.show()\n",
    "- 화면 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1682483761158,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "WhHEL42ZvfiP",
    "outputId": "714a1a6c-7d6b-4ff5-94e6-4bd29348b502"
   },
   "outputs": [],
   "source": [
    "plt.title('%i' % train_dataset[0][1])\n",
    "imshow(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.title('%i' % train_dataset[0][1])\n",
    "\n",
    "- 제목을 해당 데이터의 튜플 속 레이블로.\n",
    "\n",
    "imshow(train_dataset[0][0])\n",
    "- plt.imshow구현 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1682483829215,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "0Eo_vLGk2HlW",
    "outputId": "c1bdbb55-b3e2-47ab-b051-90d96676c5af"
   },
   "outputs": [],
   "source": [
    "print(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 출력 결과는 transform=transforms.ToTensor()로 인해 torch.Tensor 객체.\n",
    "- shape: (1,28,28)\n",
    "- type: torch.float32\n",
    "- 값은 0~1 사이 실수로 이뤄진 3차원 텐서. 값이 0~255범위 정수로 유지되는 numpy 배열과는 다르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1682483984222,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "jDh-bpoW2dTh",
    "outputId": "f441150e-2627-4b70-c13a-b861416d6a3f"
   },
   "outputs": [],
   "source": [
    "#Compose함수로 데이터 변환 여러 가지를 묶어줌\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='MNIST_data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='MNIST_data', \n",
    "                                        train=False, \n",
    "                                        download=True, \n",
    "                                        transform=transform)\n",
    "print('number of training data : ', len(train_dataset))\n",
    "print('number of test data : ', len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Compose함수로 데이터 변환 여러 가지를 묶어줌\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5))])\n",
    "\n",
    "transforms.ToTensor()\n",
    "PIL 이미지 -> PyTorch 텐서로 변환, 픽셀값 0~1의 실수로 자동 정규화.\n",
    "\n",
    "transforms.Normalize((0.5),(0.5))\n",
    "평균, 표준편차는 0.5라는 의미.\n",
    "각 채널별로 (x-0.5)/0.5 연산 수행. 픽셀값 -1~1 범위로 변환.\n",
    "\n",
    "나머지는 기존과 같이 데이터셋 세팅.\n",
    "\n",
    "print('number of training data : ', len(train_dataset))\n",
    "print('number of test data : ', len(test_dataset))\n",
    "학습 데이터와 검증 데이터 수 출력.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1682484184268,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "UPWbP-qZ3DQz",
    "outputId": "0d773c75-1799-4379-e960-221110d957bf"
   },
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터와 검증 데이터 특성 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1682484334432,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "MyGLP7pk30FC"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray' )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<plt.imshow() 구현>\n",
    "\n",
    "npimg = img.numpy()\n",
    "- PIL이미지인 img -> numpy배열인 npimg로 변환.\n",
    "\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray' )\n",
    "- PyTorch 이미지 텐서는 (채널, 높이, 너비)순.\n",
    "- matplotlib는 (높이, 너비, 채널)순서를 기대하므로, np.transpose로 (0,1,2)에서 (1,2,0)으로 차원 순서 바꿔주기.\n",
    "- cmap='gray'는 흑백 이미지를 그레이스케일로 표시.\n",
    "\n",
    "plt.show()\n",
    "- 화면 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 845,
     "status": "ok",
     "timestamp": 1682484345377,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "jFNWVxCS4Yik",
    "outputId": "a6d2ed00-76d3-4a1c-af59-1b9bc93c7d3e"
   },
   "outputs": [],
   "source": [
    "imshow(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imshow(train_dataset[0][0])\n",
    "- plt.imshow구현 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1682484865019,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "MMy-KJXN4a-S",
    "outputId": "0e547824-514e-47c5-cdd2-67da33be5797"
   },
   "outputs": [],
   "source": [
    "print(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5),(0.5))])\n",
    "\n",
    "transforms.ToTensor()\n",
    "PIL 이미지 -> PyTorch 텐서로 변환, 픽셀값 0~1의 실수로 자동 정규화.\n",
    "\n",
    "transforms.Normalize((0.5),(0.5))\n",
    "평균, 표준편차는 0.5라는 의미.\n",
    "각 채널별로 (x-0.5)/0.5 연산 수행. 픽셀값 -1~1 범위로 변환.\n",
    "\n",
    "이전의 Compose내 transform이 수행된 train_dataset[0][0] 출력.\n",
    "\n",
    "torch.Tensor 타입이고, 픽셀값은 -1~1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1682485749254,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "_K0csTU85E3n"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=64, \n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.manual_seed(1)\n",
    "랜덤 시드 고정. -> 데이터 섞기에서 결과가 항상 동일.\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=64, \n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=False) \n",
    "                                           \n",
    "- 변환이 수행된 학습데이터와 검증데이터를 불러오는 각각의 DataLoader 생성.\n",
    "- batch_size=64: 한 번에 64개 샘플씩 가져옴.\n",
    "- shuffle=True: epoch마다 데이터를 무작위로 섞는다.(학습 성능 향상에 도움)\n",
    "- shuffle=False: 테스트 데이터는 섞지 않고 순서대로 평가.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1682484927440,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "Al4Jwp015ZDn",
    "outputId": "4df1fb1f-8671-447a-e5ce-15e5612e1537"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataiter = iter(train_loader)\n",
    "이터레이터 생성\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "첫 번째 배치 꺼내기. \n",
    "\n",
    "\n",
    "64: 배치 크기 \n",
    "1: 채널 수\n",
    "28 : 이미지의 높이와 너비\n",
    "\n",
    "64: 배치 크기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1682485204479,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "-ZBZ_7ZX6Nqu",
    "outputId": "780d1053-e6f4-4859-bc55-a2b9ff92f4aa"
   },
   "outputs": [],
   "source": [
    "print(images[0].squeeze().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "squeeze()로 첫 번째 batch의 텐서의 shape에서 크기 1인 차원(채널 차원)제거 후 남은 차원 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1682485223497,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "Y4fiQgo77tIk",
    "outputId": "1d828488-447e-4248-99d0-e7d661a6dd7f"
   },
   "outputs": [],
   "source": [
    "print(images[0][0].shape) #위와 같은 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 batch의 첫 번째 이미지 채널만 선택해 차원 크기 출력. 위와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1682485752875,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "WuulHv6K7xrp",
    "outputId": "2c4b5dd6-b436-4a09-ba20-c16f075202bf"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[0].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.imshow(images[0].squeeze(), cmap='gray')\n",
    "\n",
    "- 현재 배치의 첫 번째 이미지를 squeeze()로 차원 축소 후, Matplotlib를 사용해 흑백(cmap='gray')으로 표시. 이 이미지는 Normalize((0.5), (0.5)) 변환이 적용되어 픽셀 값이 [-1, 1] 범위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "executionInfo": {
     "elapsed": 3434,
     "status": "ok",
     "timestamp": 1682485808480,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "muv1J_Je71kU",
    "outputId": "485cb276-fc36-4180-b411-1ba8c0e4a69e"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 513,
     "status": "ok",
     "timestamp": 1682486222778,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "KDlOdMzm98_w"
   },
   "outputs": [],
   "source": [
    "#Numpy 순서에 맞게 변환\n",
    "def imshow_grid(img):\n",
    "  img = img / 2 + 0.5\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKUW08Fr_t5S"
   },
   "source": [
    "* 파이토치는 3차원 image data를 C,W,H 순서로 저장 -> Channel First\n",
    "* Matplotlib을 이용하여 영상을 출력하려면 W,H,C로 변경해줘야함 -> Channel Last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1682486225161,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "S39qjkbm_WwQ",
    "outputId": "7f846710-4596-4b80-af3f-7bd583d686fd"
   },
   "outputs": [],
   "source": [
    "output = torchvision.utils.make_grid(images[:6])\n",
    "#image 출력\n",
    "imshow_grid(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output = torchvision.utils.make_grid(images[:6])\n",
    "- 현재 배치(images)에서 첫 6개의 이미지를 슬라이싱해 하나의 이미지 그리드로 만듦."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1682486449209,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "PgRQRx1H_jrI"
   },
   "outputs": [],
   "source": [
    "#CNN 모델 생성\n",
    "model =nn.Sequential(\n",
    "    nn.Conv2d(1,10,kernel_size=5,padding=1),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Conv2d(10,20,kernel_size=5,stride=1),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(4*4*20, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model =nn.Sequential(...): nn.Sequential 컨테이너를 사용해 CNN 모델을 순차적으로 정의.\n",
    "\n",
    "nn.Conv2d(1,10,kernel_size=5,padding=1): 첫 번째 합성곱 계층.\n",
    "    (in_channels=1): 입력 채널 수 (MNIST는 흑백이므로 1).\n",
    "    (out_channels=10): 출력 채널 수 (생성할 특징 맵의 수).\n",
    "    (kernel_size=5): 5*5 크기의 필터(커널)을 사용.\n",
    "    (padding=1) 입력 이미지의 가장자리에 1픽셀의 패딩을 추가하여 출력 크기 감소를 줄임.\n",
    "\n",
    "nn.MaxPool2d(2,2): 첫 번째 맥스 풀링 계층. 2x2 크기의 윈도우를 사용하여 각 윈도우 내의 최댓값을 선택하고, 스트라이드도 2로 설정하여 특징 맵의 크기를 가로세로 각각 절반으로 줄임.\n",
    "\n",
    "nn.ReLU(): ReLU(Rectified Linear Unit) 활성화 함수를 적용.\n",
    "\n",
    "nn.Conv2d(10,20,kernel_size=5,padding=1): 두 번째 합성곱 계층.\n",
    "    (in_channels=10): 이전 계층의 출력 채널 수.\n",
    "    (out_channels=20): 출력 채널 수 (생성할 특징 맵의 수).\n",
    "    (kernel_size=5): 5*5 크기의 필터(커널)을 사용.\n",
    "    (stride=1) 필터를 한 번에 1픽셀씩 이동시.\n",
    "\n",
    "nn.MaxPool2d(2,2): 두 번째 맥스 풀링 계층.\n",
    "\n",
    "nn.ReLU(): ReLU(Rectified Linear Unit) 활성화 함수를 적용.\n",
    "\n",
    "nn.Flatten(): 다차원 특징 맵을 1차원 벡터로 평탄화.\n",
    "\n",
    "nn.Linear(4*4*20, 10): 완전 연결(선형) 계층.\n",
    "\n",
    "    (in_features=4*4*20)\n",
    "- 입력 특징의 수. 이 값은 이전 합성곱 및 풀링 계층을 거치면서 계산된 특징 맵의 크기(4x4)와 채널 수(20)를 곱한 값입니다.\n",
    "\n",
    "    (out_features=10)\n",
    "- 출력 특징의 수 (MNIST는 0부터 9까지 10개의 클래스)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1682486470483,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "VTTBw4DcAc8r",
    "outputId": "85574a72-78fc-40f9-c722-373630e5580c"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.manual_seed(1): 난수 시드를 1로 고정하여 가중치 초기화 등의 과정에서 재현성을 확보.\n",
    "\n",
    "model = model.to(device): 정의된 model을 device 변수에 설정된 장치(CPU 또는 GPU)로 옮김.\n",
    "\n",
    "model: 모델의 구조를 출력. 각 계층의 상세 정보(입출력 채널, 커널 크기, 스트라이드, 패딩 등)를 보여줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1682486603968,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "tXERUsZ6AiC0"
   },
   "outputs": [],
   "source": [
    "#모델 학습\n",
    "learning_rate = 0.001\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_rate = 0.001: 학습률(learning rate)을 0.001로 설정. 학습률은 모델 파라미터를 업데이트하는 정도를 결정.\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(): 손실 함수로 교차 엔트로피 손실(Cross-Entropy Loss)을 사용. 이 함수는 다중 클래스 분류 문제에 일반적으로 사용되며, 내부적으로 Softmax 함수를 포함.\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate): 최적화 알고리즘으로 Adam(Adaptive Moment Estimation)을 사용.\n",
    "\n",
    "    model.parameters(): 모델의 학습 가능한 모든 파라미터(가중치, 편향 등)를 최적화 대상으\n",
    "    로 전달.\n",
    "    \n",
    "    lr=learning_rate: 최적화 알고리즘에 사용할 학습률을 지정.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413943,
     "status": "ok",
     "timestamp": 1682487042675,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "nh45Ncx_BCus",
    "outputId": "7feaaf57-c912-486f-bcbe-6a9139f36a18"
   },
   "outputs": [],
   "source": [
    "#epoch당 손실함수 출력\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    avg_loss = 0.0   \n",
    "\n",
    "    for images, labels in train_loader:             \n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step()         \n",
    "        \n",
    "        avg_loss += loss    \n",
    "    avg_loss= avg_loss / len(train_loader)  \n",
    "    print('Epoch : {:4d}/{:2d}, Loss = {:.5f}'.format( epoch+1, n_epochs, avg_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "n_epochs = 10: 전체 학습 데이터셋을 10번 반복하여 학습하도록 에폭 수를 설정.\n",
    "\n",
    "for epoch in range(n_epochs):: 에폭 수만큼 반복하는 외부 루프.\n",
    "\n",
    "    avg_loss = 0.0: 현재 에폭의 평균 손실을 저장할 변수를 0.0으로 초기화.\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "    - 학습 데이터 로더(train_loader)에서 배치(batch) 단위로 이미지와 해당 레이블을 가져오는 내부 루프.\n",
    "\n",
    "        images=images.to(device): 현재 배치의 이미지 데이터를 device(CPU 또는 GPU)로 옮김.\n",
    "        \n",
    "        labels=labels.to(device): 현재 배치의 레이블 데이터를 device로 옮김.\n",
    "        \n",
    "        outputs = model(images): 모델에 현재 배치의 이미지를 입력으로 넣어 예측값(outputs)을 얻음(순전파).\n",
    "        \n",
    "        loss = loss_function(outputs, labels): 모델의 예측값과 실제 레이블을 사용하여 손실(loss)을 계산.\n",
    "        \n",
    "        optimizer.zero_grad(): 이전 배치의 기울기(gradient) 값을 초기화. PyTorch는 기울기를 누적하므로, 각 배치마다 새로 계산하기 전에 초기화해야 함.\n",
    "        \n",
    "        loss.backward(): 계산된 손실에 대한 기울기를 역전파(backpropagation) 알고리즘을 통해 계산.\n",
    "        \n",
    "        optimizer.step(): 계산된 기울기를 사용하여 모델의 학습 가능한 파라미터들을 업데이트.\n",
    "        \n",
    "        avg_loss += loss: 현재 배치의 손실을 avg_loss에 누적. (주의: loss는 텐서이므로, 스칼라 값을 더하려면 loss.item()을 사용하는 것이 일반적. 여기서는 텐서 자체를 더하고 나중에 평균을 낸다.)\n",
    "\n",
    "avg_loss= avg_loss / len(train_loader): 에폭의 평균 손실을 계산. len(train_loader)는 총 배치 수.\n",
    "\n",
    "print(...): 현재 에폭 번호와 해당 에폭의 평균 손실을 지정된 형식으로 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3763,
     "status": "ok",
     "timestamp": 1682487102867,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "gPTbQWlJBIzs",
    "outputId": "b1975a4e-ce0a-483b-b16b-0445e777b7c0"
   },
   "outputs": [],
   "source": [
    "# Test model using test data\n",
    "with torch.no_grad():\n",
    "    images = test_dataset.data.view(-1, 1, 28, 28).float()\n",
    "    labels = test_dataset.targets  \n",
    "    images=images.to(device)\n",
    "    labels=labels.to(device)\n",
    "    outputs = model(images)  \n",
    "    predicted = torch.argmax(outputs, dim=1) == labels   \n",
    "    accuracy = predicted.float().mean()\n",
    "    print('Test Data Accuracy = {:.5f}'.format( accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with torch.no_grad():: 이 블록 내에서는 기울기 계산을 수행하지 않도록 설정. 모델 평가 시에는 파라미터 업데이트가 필요 없으므로 메모리 사용량을 줄이고 계산 속도를 높일 수 있다.\n",
    "\n",
    "    images = test_dataset.data.view(-1, 1, 28, 28).float(): \n",
    "    - 테스트 데이터셋의 모든 이미지(test_dataset.data)를 가져와 모델 입력 형태에 맞게 차원을 변경(.view(-1, 1, 28, 28))하고, 타입을 float으로 변환. -1은 해당 차원의 크기를 자동으로 계산하도록 하며, 여기서는 전체 이미지 수를 의미. MNIST 이미지는 원래 (10000, 28, 28) 형태인데, 채널 차원(1)을 추가하여 (10000, 1, 28, 28)로 만듦.\n",
    "    \n",
    "    labels = test_dataset.targets: 테스트 데이터셋의 모든 실제 레이블을 가져옴.\n",
    "    \n",
    "    images=images.to(device): 이미지 데이터를 device로 옮김.\n",
    "    \n",
    "    labels=labels.to(device): 레이블 데이터를 device로 옮김.\n",
    "    \n",
    "    outputs = model(images): 모델에 전체 테스트 이미지를 입력하여 예측값을 얻는다.\n",
    "    \n",
    "    predicted = torch.argmax(outputs, dim=1) == labels: \n",
    "    - 모델의 출력(outputs)에서 각 샘플에 대해 가장 높은 값을 갖는 클래스의 인덱스(즉, 예측된 클래스)를 torch.argmax(outputs, dim=1)로 찾음. dim=1은 클래스 점수/확률이 있는 차원을 따라 최댓값을 찾도록 지정. 이 예측된 클래스와 실제 레이블(labels)을 비교하여 각 샘플에 대해 예측이 맞았는지(True) 틀렸는지(False)를 나타내는 불리언(boolean) 텐서를 생성.\n",
    "    \n",
    "    accuracy = predicted.float().mean(): 불리언 텐서 predicted를 float 타입으로 변환. (True는 1.0, False는 0.0). 그런 다음 .mean() 함수를 사용하여 전체 예측 중 맞은 예측의 비율, 즉 정확도를 계산.\n",
    "    \n",
    "    print(...): 테스트 데이터에 대한 정확도를 지정된 형식으로 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1682487346712,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "188l3vkDC70h",
    "outputId": "76035052-cf9c-4b9b-e68f-f36e499a2e3e"
   },
   "outputs": [],
   "source": [
    "#torch.argmax()사용 예시\n",
    "torch.manual_seed(1)\n",
    "a = torch.randn(5,3)\n",
    "print(a)\n",
    "torch.argmax(a, dim =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.manual_seed(1): 난수 시드를 1로 고정.\n",
    "\n",
    "a = torch.randn(5,3): 평균 0, 표준편차 1의 정규 분포에서 샘플링된 값으로 채워진 5x3 크기의 텐서 a를 생성.\n",
    "\n",
    "print(a): 생성된 텐서 a를 출력.\n",
    "\n",
    "torch.argmax(a, dim =1): 텐서 a의 각 행(dim=1은 행을 따라 연산)에서 최댓값을 갖는 요소의 인덱스를 반환. 결과는 각 행별 최댓값 인덱스를 담은 1차원 텐서."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2100,
     "status": "ok",
     "timestamp": 1682487383890,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "eTskxlrWD4Iy",
    "outputId": "c993e78d-ca60-4f79-8b27-e28703103402"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    images = test_dataset.data.view(-1, 1, 28, 28).float()\n",
    "    labels = test_dataset.targets    \n",
    "    images=images.to(device)\n",
    "    labels=labels.to(device)    \n",
    "    outputs = model(images)  \n",
    "    predicted = torch.max(outputs, dim=1)[1] ==labels #argmax대신 max를 이용하여 계산\n",
    "    accuracy = predicted.float().mean()\n",
    "    print('Test Data Accuracy = {:.5f}'.format( accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  #Test model using test data 와 거의 동일한 모델 평가 코드\n",
    "images, labels device에 로드 후 images를 모델에 입력.\n",
    "predicted = torch.max(outputs, dim=1)[1] ==labels: #argmax대신 max를 이용하여 계산\n",
    "- torch.max(outputs, dim=1) 함수는 지정된 차원(dim=1)을 따라 각 행의 최댓값과 해당 최댓값의 인덱스를 모두 반환하는 튜플 (values, indices)을 생성. 여기서 [1]을 사용하여 인덱스만 선택하고, 이를 실제 레이블과 비교. 이는 torch.argmax()와 동일한 결과."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1682487630219,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "NfMU9Dl8EA1g"
   },
   "outputs": [],
   "source": [
    "#과정 재정리\n",
    "torch.manual_seed(1)\n",
    "#Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=64,\n",
    "                                           shuffle=False)\n",
    "model =nn.Sequential(\n",
    "    nn.Conv2d(1,10,kernel_size=5,padding=1),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Conv2d(10,20,kernel_size=5,stride=1),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(4*4*20, 10)\n",
    ")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = model.to(device)\n",
    "model\n",
    "learning_rate = 0.001\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr =learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로딩 -> 모델 정의 -> 최적화 설정\n",
    "\n",
    "[데이터 로딩]\n",
    "torch.manual_seed(1)\n",
    "- 이전과 같은 시드 사용.\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=64, \n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=False) \n",
    "                                           \n",
    "- 변환이 수행된 학습데이터와 검증데이터를 불러오는 각각의 DataLoader 생성.\n",
    "- batch_size=64: 한 번에 64개 샘플씩 가져옴.\n",
    "- shuffle=True: epoch마다 데이터를 무작위로 섞는다.(학습 성능 향상에 도움)\n",
    "- shuffle=False: 테스트 데이터는 섞지 않고 순서대로 평가.\n",
    "\n",
    "[모델 정의]\n",
    "model =nn.Sequential(...): nn.Sequential 컨테이너를 사용해 CNN 모델을 순차적으로 정의.\n",
    "\n",
    "nn.Conv2d(1,10,kernel_size=5,padding=1): 첫 번째 합성곱 계층.\n",
    "    (in_channels=1): 입력 채널 수 (MNIST는 흑백이므로 1).\n",
    "    (out_channels=10): 출력 채널 수 (생성할 특징 맵의 수).\n",
    "    (kernel_size=5): 5*5 크기의 필터(커널)을 사용.\n",
    "    (padding=1) 입력 이미지의 가장자리에 1픽셀의 패딩을 추가하여 출력 크기 감소를 줄임.\n",
    "\n",
    "nn.MaxPool2d(2,2): 첫 번째 맥스 풀링 계층. 2x2 크기의 윈도우를 사용하여 각 윈도우 내의 최댓값을 선택하고, 스트라이드도 2로 설정하여 특징 맵의 크기를 가로세로 각각 절반으로 줄임.\n",
    "\n",
    "nn.ReLU(): ReLU(Rectified Linear Unit) 활성화 함수를 적용.\n",
    "\n",
    "nn.Conv2d(10,20,kernel_size=5,padding=1): 두 번째 합성곱 계층.\n",
    "    (in_channels=10): 이전 계층의 출력 채널 수.\n",
    "    (out_channels=20): 출력 채널 수 (생성할 특징 맵의 수).\n",
    "    (kernel_size=5): 5*5 크기의 필터(커널)을 사용.\n",
    "    (stride=1) 필터를 한 번에 1픽셀씩 이동시.\n",
    "\n",
    "nn.MaxPool2d(2,2): 두 번째 맥스 풀링 계층.\n",
    "\n",
    "nn.ReLU(): ReLU(Rectified Linear Unit) 활성화 함수를 적용.\n",
    "\n",
    "nn.Flatten(): 다차원 특징 맵을 1차원 벡터로 평탄화.\n",
    "\n",
    "nn.Linear(4*4*20, 10): 완전 연결(선형) 계층.\n",
    "\n",
    "    (in_features=4*4*20)\n",
    "- 입력 특징의 수. 이 값은 이전 합성곱 및 풀링 계층을 거치면서 계산된 특징 맵의 크기(4x4)와 채널 수(20)를 곱한 값입니다.\n",
    "\n",
    "    (out_features=10)\n",
    "- 출력 특징의 수 (MNIST는 0부터 9까지 10개의 클래스).\n",
    "\n",
    "torch.manual_seed(1): 난수 시드를 1로 고정하여 가중치 초기화 등의 과정에서 재현성을 확보.\n",
    "\n",
    "model = model.to(device): 정의된 model을 device 변수에 설정된 장치(CPU 또는 GPU)로 옮김.\n",
    "\n",
    "model: 모델의 구조를 출력. 각 계층의 상세 정보(입출력 채널, 커널 크기, 스트라이드, 패딩 등)를 보여줌.\n",
    "\n",
    "[최적화 설정]\n",
    "\n",
    "learning_rate = 0.001: 학습률(learning rate)을 0.001로 설정. 학습률은 모델 파라미터를 업데이트하는 정도를 결정.\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(): 손실 함수로 교차 엔트로피 손실(Cross-Entropy Loss)을 사용. 이 함수는 다중 클래스 분류 문제에 일반적으로 사용되며, 내부적으로 Softmax 함수를 포함.\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate): 최적화 알고리즘으로 Adam(Adaptive Moment Estimation)을 사용.\n",
    "\n",
    "    model.parameters(): 모델의 학습 가능한 모든 파라미터(가중치, 편향 등)를 최적화 대상으\n",
    "    로 전달.\n",
    "    \n",
    "    lr=learning_rate: 최적화 알고리즘에 사용할 학습률을 지정.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7MvPgGSGqgn"
   },
   "source": [
    "지금까지 내용 통합하여 재정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 519,
     "status": "ok",
     "timestamp": 1682488402079,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "iN7iYnswGn5A"
   },
   "outputs": [],
   "source": [
    "#손실함수 그래프 그리기\n",
    "torch.manual_seed(10)\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=64, \n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=False) \n",
    "model =nn.Sequential(\n",
    "    nn.Conv2d(1,10,kernel_size=5,padding=1),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Conv2d(10,20,kernel_size=5,stride=1),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(4*4*20, 10)\n",
    ")      \n",
    "    \n",
    "torch.manual_seed(1)\n",
    "model = model.to(device)  \n",
    "model\n",
    "\n",
    "learning_rate = 0.001\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로딩 -> 모델 정의 -> 최적화 설정\n",
    "\n",
    "[데이터 로딩]\n",
    "torch.manual_seed()\n",
    "- 이전과 다른 시드 사용.\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=64, \n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=False) \n",
    "                                           \n",
    "- 변환이 수행된 학습데이터와 검증데이터를 불러오는 각각의 DataLoader 생성.\n",
    "- batch_size=64: 한 번에 64개 샘플씩 가져옴.\n",
    "- shuffle=True: epoch마다 데이터를 무작위로 섞는다.(학습 성능 향상에 도움)\n",
    "- shuffle=False: 테스트 데이터는 섞지 않고 순서대로 평가.\n",
    "\n",
    "[모델 정의]\n",
    "model =nn.Sequential(...): nn.Sequential 컨테이너를 사용해 CNN 모델을 순차적으로 정의.\n",
    "\n",
    "nn.Conv2d(1,10,kernel_size=5,padding=1): 첫 번째 합성곱 계층.\n",
    "    (in_channels=1): 입력 채널 수 (MNIST는 흑백이므로 1).\n",
    "    (out_channels=10): 출력 채널 수 (생성할 특징 맵의 수).\n",
    "    (kernel_size=5): 5*5 크기의 필터(커널)을 사용.\n",
    "    (padding=1) 입력 이미지의 가장자리에 1픽셀의 패딩을 추가하여 출력 크기 감소를 줄임.\n",
    "\n",
    "nn.MaxPool2d(2,2): 첫 번째 맥스 풀링 계층. 2x2 크기의 윈도우를 사용하여 각 윈도우 내의 최댓값을 선택하고, 스트라이드도 2로 설정하여 특징 맵의 크기를 가로세로 각각 절반으로 줄임.\n",
    "\n",
    "nn.ReLU(): ReLU(Rectified Linear Unit) 활성화 함수를 적용.\n",
    "\n",
    "nn.Conv2d(10,20,kernel_size=5,padding=1): 두 번째 합성곱 계층.\n",
    "    (in_channels=10): 이전 계층의 출력 채널 수.\n",
    "    (out_channels=20): 출력 채널 수 (생성할 특징 맵의 수).\n",
    "    (kernel_size=5): 5*5 크기의 필터(커널)을 사용.\n",
    "    (stride=1) 필터를 한 번에 1픽셀씩 이동시.\n",
    "\n",
    "nn.MaxPool2d(2,2): 두 번째 맥스 풀링 계층.\n",
    "\n",
    "nn.ReLU(): ReLU(Rectified Linear Unit) 활성화 함수를 적용.\n",
    "\n",
    "nn.Flatten(): 다차원 특징 맵을 1차원 벡터로 평탄화.\n",
    "\n",
    "nn.Linear(4*4*20, 10): 완전 연결(선형) 계층.\n",
    "\n",
    "    (in_features=4*4*20)\n",
    "- 입력 특징의 수. 이 값은 이전 합성곱 및 풀링 계층을 거치면서 계산된 특징 맵의 크기(4x4)와 채널 수(20)를 곱한 값입니다.\n",
    "\n",
    "    (out_features=10)\n",
    "- 출력 특징의 수 (MNIST는 0부터 9까지 10개의 클래스).\n",
    "\n",
    "torch.manual_seed(1): 난수 시드를 1로 고정하여 가중치 초기화 등의 과정에서 재현성을 확보.\n",
    "\n",
    "model = model.to(device): 정의된 model을 device 변수에 설정된 장치(CPU 또는 GPU)로 옮김.\n",
    "\n",
    "model: 모델의 구조를 출력. 각 계층의 상세 정보(입출력 채널, 커널 크기, 스트라이드, 패딩 등)를 보여줌.\n",
    "\n",
    "[최적화 설정]\n",
    "\n",
    "learning_rate = 0.001: 학습률(learning rate)을 0.001로 설정. 학습률은 모델 파라미터를 업데이트하는 정도를 결정.\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(): 손실 함수로 교차 엔트로피 손실(Cross-Entropy Loss)을 사용. 이 함수는 다중 클래스 분류 문제에 일반적으로 사용되며, 내부적으로 Softmax 함수를 포함.\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate): 최적화 알고리즘으로 Adam(Adaptive Moment Estimation)을 사용.\n",
    "\n",
    "    model.parameters(): 모델의 학습 가능한 모든 파라미터(가중치, 편향 등)를 최적화 대상으\n",
    "    로 전달.\n",
    "    \n",
    "    lr=learning_rate: 최적화 알고리즘에 사용할 학습률을 지정.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 467479,
     "status": "ok",
     "timestamp": 1682488879327,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "99Gxw0TpH6ic"
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "train_losses=[]\n",
    "test_losses=[]\n",
    "train_accuracy=[]\n",
    "test_accuracy=[]\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    for images, labels in train_loader: \n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step()         \n",
    "               \n",
    "        epoch_loss += loss.item()/len(train_loader)\n",
    "        acc = ((outputs.argmax(dim=1) == labels).float().mean())\n",
    "        epoch_accuracy += acc.item()/len(train_loader)\n",
    "    train_losses.append(epoch_loss)  \n",
    "    train_accuracy.append(epoch_accuracy)  \n",
    "#    print('Epoch : {}, train loss : {:.5f}, train accuracy : {:.5f}'.format(epoch+1, epoch_loss, epoch_accuracy))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        epoch_test_accuracy=0\n",
    "        epoch_test_loss =0\n",
    "        for images, labels in test_loader:          \n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "            test_output = model(images)\n",
    "            test_loss = loss_function(test_output,labels)\n",
    "            \n",
    "            epoch_test_loss += test_loss.item()/ len(test_loader)\n",
    "            acc = ((test_output.argmax(dim=1) == labels).float().mean())\n",
    "            epoch_test_accuracy += acc.item()/ len(test_loader)\n",
    "        test_losses.append(epoch_test_loss) \n",
    "        test_accuracy.append(epoch_test_accuracy)  \n",
    "#        print('Epoch : {}, test loss : {:.5f}, test accuracy : {:.5f}'.format(epoch+1, epoch_test_loss, epoch_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 변수 초기화\n",
    "\n",
    "이 셀은 모델을 10 에폭 동안 학습시키면서, 각 에폭이 끝날 때마다 학습 데이터셋과 테스트 데이터셋에 대한 평균 손실 및 정확도를 계산하여 각각의 리스트(train_losses, test_losses, train_accuracy, test_accuracy)에 저장.\n",
    "\n",
    "2. 에폭 루프: 전체 학습 n_epochs만큼 반복.\n",
    "\n",
    "- epoch_loss, epoch_accuracy: 한 에폭 동안의 누적 손실과 정확도를 저장할 변수\n",
    "\n",
    "\n",
    "3. 학습 단계:\n",
    "   \n",
    "for images, labels in train_loader: 학습 데이터 전체를 배치 단위로 반복.\n",
    "\n",
    "images, labels = images.to(device), labels.to(device): 데이터를 GPU 또는 CPU로 이동.\n",
    "\n",
    "outputs = model(images): 모델에 이미지를 입력해 예측 결과(로짓)를 얻는다.\n",
    "\n",
    "loss = loss_function(outputs, labels): 예측 결과와 실제 정답 레이블을 비교하여 손실값을 계산.\n",
    "\n",
    "optimizer.zero_grad(): 이전 배치에서 계산된 기울기(gradient)를 초기화.\n",
    "\n",
    "loss.backward(): 손실을 모델 파라미터에 대해 역전파(backpropagation)하여 기울기를 계산.\n",
    "\n",
    "optimizer.step(): 계산된 기울기를 이용해 모델 파라미터를 업데이트.\n",
    "\n",
    "epoch_loss += loss.item()/len(train_loader): 현재 배치의 손실값을 전체 배치 개수로 나눠 누적(평균 손실 계산).\n",
    "\n",
    "acc = ((outputs.argmax(dim=1) == labels).float().mean()): 각 배치에서 예측값과 정답이 일치하는 비율(정확도)을 계산.\n",
    "\n",
    "epoch_accuracy += acc.item()/len(train_loader): 배치별 정확도를 전체 배치 개수로 나눠 누적(평균 정확도 계산).\n",
    "\n",
    "- loss.item()과 acc.item(): 텐서에서 스칼라 값을 추출하여 누적 합계에 사용합니다. 이렇게 해야 메모리 누수를 방지하고 정확한 평균값을 계산할 수 있다.\n",
    "\n",
    "train_losses.append(epoch_loss), train_accuracy.append(epoch_accuracy): 한 에폭이 끝나면 평균 손실과 정확도를 리스트에 저장.\n",
    "\n",
    "\n",
    "\n",
    "4. 평가 단계\n",
    "with torch.no_grad(): 평가 단계에서는 기울기 계산이 필요 없으므로 메모리와 연산을 절약.\n",
    "\n",
    "for images, labels in test_loader: 테스트 데이터를 배치 단위로 반복.\n",
    "\n",
    "images, labels = images.to(device), labels.to(device): 데이터를 device로 이동.\n",
    "\n",
    "test_output = model(images): 모델에 입력해 예측 결과를 얻는다.\n",
    "\n",
    "test_loss = loss_function(test_output,labels): 예측값과 정답을 비교해 손실을 계산.\n",
    "\n",
    "epoch_test_loss += test_loss.item()/ len(test_loader): 배치 손실을 전체 배치 개수로 나눠 누적(평균 손실).\n",
    "\n",
    "acc = ((test_output.argmax(dim=1) == labels).float().mean()): 배치 정확도 계산.\n",
    "\n",
    "epoch_test_accuracy += acc.item()/ len(test_loader): 배치 정확도를 전체 배치 개수로 나눠 누적(평균 정확도).\n",
    "\n",
    "test_losses.append(epoch_test_loss), test_accuracy.append(epoch_test_accuracy): 한 에폭이 끝나면 평균 테스트 손실과 정확도를 리스트에 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1682488894488,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "LCo_FDqjH76v",
    "outputId": "9afa2e4a-b4d0-4e27-da39-60fda9dc2cc3"
   },
   "outputs": [],
   "source": [
    "#plot the loss function\n",
    "plt.title(\"Train and Test Loss\")\n",
    "plt.plot(range(n_epochs),train_losses, label=\"train\")\n",
    "plt.plot(range(n_epochs),test_losses, label=\"test\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.title(\"Train and Test Loss\"): 그래프의 제목을 \"Train and Test Loss\"로 설정.\n",
    "\n",
    "plt.plot(range(n_epochs),train_losses, label=\"train\"): x축을 에폭 번호(0부터 9), y축을 학습 손실(train_losses 리스트의 값)로 하여 학습 손실 곡선을 그림. label=\"train\"은 범례에 표시될 이름.\n",
    "\n",
    "plt.plot(range(n_epochs),test_losses, label=\"test\"): x축을 에폭 번호, y축을 테스트 손실(test_losses 리스트의 값)로 하여 테스트 손실 곡선을 그림. label=\"test\"는 범례에 표시될 이름.\n",
    "\n",
    "plt.xlabel('Epoch'): x축의 레이블을 'Epoch'로 설정.\n",
    "\n",
    "plt.ylabel('Loss'): y축의 레이블을 'Loss'로 설정.\n",
    "\n",
    "plt.legend(): 그래프에 범례를 표시.\n",
    "\n",
    "plt.show(): 생성된 그래프를 화면에 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 1055,
     "status": "ok",
     "timestamp": 1682488900058,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "SLVhti1cIPTn",
    "outputId": "c0ec2634-88cc-4dcf-f1ce-8b1ce3fa7c5f"
   },
   "outputs": [],
   "source": [
    "#plot the accuracy function\n",
    "plt.title(\"Train and Test accuracy\")\n",
    "plt.plot(range(n_epochs),train_accuracy, label=\"train\")\n",
    "plt.plot(range(n_epochs),test_accuracy, label=\"test\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.title(\"Train and Test accuracy\"): 그래프의 제목을 \"Train and Test accuracy\"로 설정.\n",
    "\n",
    "plt.plot(range(n_epochs),train_accuracy, label=\"train\"): x축을 에폭 번호, y축을 학습 정확도(train_accuracy 리스트의 값)로 하여 학습 정확도 곡선을 그림.\n",
    "\n",
    "plt.plot(range(n_epochs),test_accuracy, label=\"test\"): x축을 에폭 번호, y축을 테스트 정확도(test_accuracy 리스트의 값)로 하여 테스트 정확도 곡선을 그림.\n",
    "\n",
    "plt.xlabel('Epoch'): x축의 레이블을 'Epoch'로 설정.\n",
    "\n",
    "plt.ylabel('Accuracy'): y축의 레이블을 'Accuracy'로 설정. (제공된 노트북 파일에서는 이 부분이 'Loss'로 되어 있으나, 문맥상 'Accuracy'가 맞습니다.)\n",
    "\n",
    "plt.legend(): 그래프에 범례를 표시.\n",
    "\n",
    "plt.show(): 생성된 그래프를 화면에 출력."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIYx0xxAJ2Yd"
   },
   "source": [
    "예제 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6372,
     "status": "ok",
     "timestamp": 1682489975667,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "ehf6EeUmJ3op",
    "outputId": "b78eec29-2da1-4427-c06a-239704a6be7d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리 임포트 및 장치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1115,
     "status": "ok",
     "timestamp": 1682489978820,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "QLvP0w19J8ri"
   },
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='MNIST_data',\n",
    "                          train=True, \n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='MNIST_data',\n",
    "                         train=False, \n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " MNIST 데이터셋 로드 (ToTensor 변환만 적용)\n",
    " download=False로 설정되어 있으므로, 이전에 다운로드된 로컬 데이터를 사용합니다. 만약 데이터가 없다면 오류 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1682489983208,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "Vm5cgUtYJ-eZ",
    "outputId": "db9d241d-3f56-4010-bd90-8635f38d2cff"
   },
   "outputs": [],
   "source": [
    "# Check \n",
    "print(train_dataset.data.shape)\n",
    "print(train_dataset.targets.shape)\n",
    "print(test_dataset.data.shape)\n",
    "print(test_dataset.targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dataset.data.shape: 학습 데이터셋의 이미지 데이터 텐서의 모양을 출력 \n",
    "(예: torch.Size([60000, 28, 28])).\n",
    "\n",
    "train_dataset.targets.shape: 학습 데이터셋의 레이블 텐서의 모양을 출력 \n",
    "(예: torch.Size([60000])).\n",
    "\n",
    "test_dataset.data.shape: 테스트 데이터셋의 이미지 데이터 텐서의 모양을 출력.\n",
    "\n",
    "test_dataset.targets.shape: 테스트 데이터셋의 레이블 텐서의 모양을 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1682489985814,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "-IQZqZVWKED5"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=64, \n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터셋을 위한 학습 및 테스트 데이터 로더를 생성.\n",
    "\n",
    "이전 Data Loader 셀과 동일한 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1682489991520,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "Ommih0EAKI1f"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1) \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 7 * 7 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__init__(self): 모델 계층 초기화.\n",
    "\n",
    "    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1): 첫 번째 합성곱 계층. 입력 채널 1 (흑백), 출력 채널 32, 3x3 커널, 스트라이드 1, 패딩 1.\n",
    "    \n",
    "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2): 첫 번째 맥스 풀링 계층.\n",
    "    \n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1): 두 번째 합성곱 계층. 입력 채널 32, 출력 채널 64.\n",
    "    \n",
    "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2): 두 번째 맥스 풀링 계층.\n",
    "    \n",
    "    self.fc1 = nn.Linear(7 * 7 * 64, 128): 첫 번째 완전 연결 계층. 입력 특징 수는 7x7x64=3136 (28x28 이미지가 두 번의 2x2 풀링을 거치면 7x7이 되고, 채널 수는 64). 출력 특징 수는 128. \n",
    "    \n",
    "    self.fc2 = nn.Linear(128, 10): 두 번째 완전 연결 계층(출력 계층). 입력 특징 수 128, 출력 특징 수 10 (0~9 숫자 클래스).\n",
    "\n",
    "forward(self, x): 모델의 순전파(forward pass) 과정 정의.\n",
    "\n",
    "    x = self.pool1(F.relu(self.conv1(x))): 입력 x는 conv1 -> ReLU 활성화 -> pool1을 순차적으로 통과.\n",
    "    \n",
    "    x = self.pool2(F.relu(self.conv2(x))): 이전 결과는 conv2 -> ReLU 활성화 -> pool2를 순차적으로 통과.\n",
    "    \n",
    "    x = x.view(-1, 7 * 7 * 64): 다차원 특징 맵을 완전 연결 계층에 입력하기 위해 1차원 벡터로 평탄화. -1은 배치 크기를 유지하도록 자동으로 계산.\n",
    "    \n",
    "    x = F.relu(self.fc1(x)): fc1 -> ReLU 활성화를 통과.\n",
    "    \n",
    "    x = self.fc2(x): fc2(출력 계층)를 통과. 일반적으로 분류 문제에서는 이 출력에 Softmax 함수를 적용하지만, nn.CrossEntropyLoss를 사용하면 내부적으로 Softmax가 처리되므로 여기서는 생략.\n",
    "    \n",
    "    return x: 모델의 최종 출력을 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 943,
     "status": "ok",
     "timestamp": 1682489994798,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "UlMyK7sOKsdw",
    "outputId": "354423a5-8791-4921-8015-b21e033cd9f9"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "model = CNN().to(device)  \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.manual_seed(1): 난수 시드를 고정.\n",
    "\n",
    "model = CNN().to(device): 위에서 정의한 CNN 클래스의 인스턴스(모델 객체) 생성, device로 옮김.\n",
    "\n",
    "model: 모델의 구조를 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 948,
     "status": "ok",
     "timestamp": 1682490088667,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "fGuNHmKoOSLd"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률, 손실 함수, 최적화 도구를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0I07klZOVb_"
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    avg_loss = 0.0   \n",
    "\n",
    "    for images, labels in train_loader:             \n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step()         \n",
    "        \n",
    "        avg_loss += loss    \n",
    "    avg_loss= avg_loss / len(train_loader)  \n",
    "    print('Epoch : {:4d}/{:2d}, Loss = {:.5f}'.format( epoch+1, n_epochs, avg_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_epochs = 10: 전체 학습 데이터셋을 10번 반복하여 학습하도록 에폭 수를 설정.\n",
    "\n",
    "for epoch in range(n_epochs):: 에폭 수만큼 반복하는 외부 루프.\n",
    "\n",
    "avg_loss = 0.0: 현재 에폭의 평균 손실을 저장할 변수를 0.0으로 초기화.\n",
    "\n",
    "for images, labels in train_loader:\n",
    "- 학습 데이터 로더(train_loader)에서 배치(batch) 단위로 이미지와 해당 레이블을 가져오는 내부 루프.\n",
    "\n",
    "    images=images.to(device): 현재 배치의 이미지 데이터를 device(CPU 또는 GPU)로 옮김.\n",
    "    \n",
    "    labels=labels.to(device): 현재 배치의 레이블 데이터를 device로 옮김.\n",
    "    \n",
    "    outputs = model(images): 모델에 현재 배치의 이미지를 입력으로 넣어 예측값(outputs)을 얻음(순전파).\n",
    "    \n",
    "    loss = loss_function(outputs, labels): 모델의 예측값과 실제 레이블을 사용하여 손실(loss)을 계산.\n",
    "    \n",
    "    optimizer.zero_grad(): 이전 배치의 기울기(gradient) 값을 초기화. PyTorch는 기울기를 누적하므로, 각 배치마다 새로 계산하기 전에 초기화해야 함.\n",
    "    \n",
    "    loss.backward(): 계산된 손실에 대한 기울기를 역전파(backpropagation) 알고리즘을 통해 계산.\n",
    "    \n",
    "    optimizer.step(): 계산된 기울기를 사용하여 모델의 학습 가능한 파라미터들을 업데이트.\n",
    "    \n",
    "    avg_loss += loss: 현재 배치의 손실을 avg_loss에 누적. (주의: loss는 텐서이므로, 스칼라 값을 더하려면 loss.item()을 사용하는 것이 일반적. 여기서는 텐서 자체를 더하고 나중에 평균을 낸다.)\n",
    "avg_loss= avg_loss / len(train_loader): 에폭의 평균 손실을 계산. len(train_loader)는 총 배치 수.\n",
    "\n",
    "print(...): 현재 에폭 번호와 해당 에폭의 평균 손실을 지정된 형식으로 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BilSLm_xOXCK"
   },
   "outputs": [],
   "source": [
    "# Test model using test data\n",
    "with torch.no_grad():\n",
    "    images = test_dataset.data.view(-1, 1, 28, 28).float()\n",
    "    labels = test_dataset.targets    \n",
    "    images=images.to(device)\n",
    "    labels=labels.to(device)    \n",
    "    outputs = model(images)  \n",
    "    predicted = torch.max(outputs, dim=1)[1] ==labels\n",
    "    accuracy = predicted.float().mean()\n",
    "    print('Test Data Accuracy = {:.5f}'.format( accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  #Test model using test data 와 거의 동일한 모델 평가 코드\n",
    "images, labels device에 로드 후 images를 모델에 입력.\n",
    "predicted = torch.max(outputs, dim=1)[1] ==labels: #argmax대신 max를 이용하여 계산\n",
    "- torch.max(outputs, dim=1) 함수는 지정된 차원(dim=1)을 따라 각 행의 최댓값과 해당 최댓값의 인덱스를 모두 반환하는 튜플 (values, indices)을 생성. 여기서 [1]을 사용하여 인덱스만 선택하고, 이를 실제 레이블과 비교. 이는 torch.argmax()와 동일한 결과."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1682490119770,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "KUvsAzQvMFj-"
   },
   "outputs": [],
   "source": [
    "#손실함수 그래프 그리기\n",
    "torch.manual_seed(1)\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=64, \n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=False) \n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1) \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 7 * 7 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = CNN().to(device)  \n",
    "model\n",
    "\n",
    "learning_rate = 0.001\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로딩 -> 모델 정의 -> 최적화 설정\n",
    "\n",
    "[데이터 로딩]\n",
    "torch.manual_seed()\n",
    "- 이전과 다른 시드 사용.\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=64, \n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=False) \n",
    "                                           \n",
    "- 변환이 수행된 학습데이터와 검증데이터를 불러오는 각각의 DataLoader 생성.\n",
    "- batch_size=64: 한 번에 64개 샘플씩 가져옴.\n",
    "- shuffle=True: epoch마다 데이터를 무작위로 섞는다.(학습 성능 향상에 도움)\n",
    "- shuffle=False: 테스트 데이터는 섞지 않고 순서대로 평가.\n",
    "\n",
    "[모델 정의]\n",
    "__init__(self): 모델 계층 초기화.\n",
    "\n",
    "self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1): 첫 번째 합성곱 계층. 입력 채널 1 (흑백), 출력 채널 32, 3x3 커널, 스트라이드 1, 패딩 1.\n",
    "    \n",
    "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2): 첫 번째 맥스 풀링 계층.\n",
    "    \n",
    "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1): 두 번째 합성곱 계층. 입력 채널 32, 출력 채널 64.\n",
    "    \n",
    "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2): 두 번째 맥스 풀링 계층.\n",
    "    \n",
    "    self.fc1 = nn.Linear(7 * 7 * 64, 128): 첫 번째 완전 연결 계층. 입력 특징 수는 7x7x64=3136 (28x28 이미지가 두 번의 2x2 풀링을 거치면 7x7이 되고, 채널 수는 64). 출력 특징 수는 128. \n",
    "    \n",
    "    self.fc2 = nn.Linear(128, 10): 두 번째 완전 연결 계층(출력 계층). 입력 특징 수 128, 출력 특징 수 10 (0~9 숫자 클래스).\n",
    "\n",
    "forward(self, x): 모델의 순전파(forward pass) 과정 정의.\n",
    "\n",
    "    x = self.pool1(F.relu(self.conv1(x))): 입력 x는 conv1 -> ReLU 활성화 -> pool1을 순차적으로 통과.\n",
    "    \n",
    "    x = self.pool2(F.relu(self.conv2(x))): 이전 결과는 conv2 -> ReLU 활성화 -> pool2를 순차적으로 통과.\n",
    "    \n",
    "    x = x.view(-1, 7 * 7 * 64): 다차원 특징 맵을 완전 연결 계층에 입력하기 위해 1차원 벡터로 평탄화. -1은 배치 크기를 유지하도록 자동으로 계산.\n",
    "    \n",
    "    x = F.relu(self.fc1(x)): fc1 -> ReLU 활성화를 통과.\n",
    "    \n",
    "    x = self.fc2(x): fc2(출력 계층)를 통과. 일반적으로 분류 문제에서는 이 출력에 Softmax 함수를 적용하지만, nn.CrossEntropyLoss를 사용하면 내부적으로 Softmax가 처리되므로 여기서는 생략.\n",
    "    \n",
    "    return x: 모델의 최종 출력을 반환.\n",
    "\n",
    "[최적화 설정]\n",
    "\n",
    "learning_rate = 0.001: 학습률(learning rate)을 0.001로 설정. 학습률은 모델 파라미터를 업데이트하는 정도를 결정.\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(): 손실 함수로 교차 엔트로피 손실(Cross-Entropy Loss)을 사용. 이 함수는 다중 클래스 분류 문제에 일반적으로 사용되며, 내부적으로 Softmax 함수를 포함.\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate): 최적화 알고리즘으로 Adam(Adaptive Moment Estimation)을 사용.\n",
    "\n",
    "    model.parameters(): 모델의 학습 가능한 모든 파라미터(가중치, 편향 등)를 최적화 대상으\n",
    "    로 전달.\n",
    "    \n",
    "    lr=learning_rate: 최적화 알고리즘에 사용할 학습률을 지정.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1061526,
     "status": "ok",
     "timestamp": 1682491197344,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "USLbTawBOdvz",
    "outputId": "a1890833-f0f7-4178-ac27-4bfc6c350927"
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "train_losses=[]\n",
    "test_losses=[]\n",
    "train_accuracy=[]\n",
    "test_accuracy=[]\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    for images, labels in train_loader: \n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step()         \n",
    "               \n",
    "        epoch_loss += loss.item()/len(train_loader)\n",
    "        acc = ((outputs.argmax(dim=1) == labels).float().mean())\n",
    "        epoch_accuracy += acc.item()/len(train_loader)\n",
    "    train_losses.append(epoch_loss)  \n",
    "    train_accuracy.append(epoch_accuracy)  \n",
    "    print('Epoch : {}, train loss : {:.5f}, train accuracy : {:.5f}'.format(epoch+1, epoch_loss, epoch_accuracy))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        epoch_test_accuracy=0\n",
    "        epoch_test_loss =0\n",
    "        for images, labels in test_loader:          \n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)\n",
    "            test_output = model(images)\n",
    "            test_loss = loss_function(test_output,labels)\n",
    "            \n",
    "            epoch_test_loss += test_loss.item()/ len(test_loader)\n",
    "            acc = ((test_output.argmax(dim=1) == labels).float().mean())\n",
    "            epoch_test_accuracy += acc.item()/ len(test_loader)\n",
    "        test_losses.append(epoch_test_loss) \n",
    "        test_accuracy.append(epoch_test_accuracy)  \n",
    "        print('Epoch : {}, test loss : {:.5f}, test accuracy : {:.5f}'.format(epoch+1, epoch_test_loss, epoch_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 변수 초기화\n",
    "\n",
    "이 셀은 모델을 10 에폭 동안 학습시키면서, 각 에폭이 끝날 때마다 학습 데이터셋과 테스트 데이터셋에 대한 평균 손실 및 정확도를 계산하여 각각의 리스트(train_losses, test_losses, train_accuracy, test_accuracy)에 저장.\n",
    "\n",
    "2. 에폭 루프: 전체 학습 n_epochs만큼 반복.\n",
    "\n",
    "- epoch_loss, epoch_accuracy: 한 에폭 동안의 누적 손실과 정확도를 저장할 변수\n",
    "\n",
    "\n",
    "3. 학습 단계:\n",
    "   \n",
    "for images, labels in train_loader: 학습 데이터 전체를 배치 단위로 반복.\n",
    "\n",
    "images, labels = images.to(device), labels.to(device): 데이터를 GPU 또는 CPU로 이동.\n",
    "\n",
    "outputs = model(images): 모델에 이미지를 입력해 예측 결과(로짓)를 얻는다.\n",
    "\n",
    "loss = loss_function(outputs, labels): 예측 결과와 실제 정답 레이블을 비교하여 손실값을 계산.\n",
    "\n",
    "optimizer.zero_grad(): 이전 배치에서 계산된 기울기(gradient)를 초기화.\n",
    "\n",
    "loss.backward(): 손실을 모델 파라미터에 대해 역전파(backpropagation)하여 기울기를 계산.\n",
    "\n",
    "optimizer.step(): 계산된 기울기를 이용해 모델 파라미터를 업데이트.\n",
    "\n",
    "epoch_loss += loss.item()/len(train_loader): 현재 배치의 손실값을 전체 배치 개수로 나눠 누적(평균 손실 계산).\n",
    "\n",
    "acc = ((outputs.argmax(dim=1) == labels).float().mean()): 각 배치에서 예측값과 정답이 일치하는 비율(정확도)을 계산.\n",
    "\n",
    "epoch_accuracy += acc.item()/len(train_loader): 배치별 정확도를 전체 배치 개수로 나눠 누적(평균 정확도 계산).\n",
    "\n",
    "- loss.item()과 acc.item(): 텐서에서 스칼라 값을 추출하여 누적 합계에 사용합니다. 이렇게 해야 메모리 누수를 방지하고 정확한 평균값을 계산할 수 있다.\n",
    "\n",
    "train_losses.append(epoch_loss), train_accuracy.append(epoch_accuracy): 한 에폭이 끝나면 평균 손실과 정확도를 리스트에 저장.\n",
    "\n",
    "+) 각 에폭의 학습 및 테스트 손실/정확도를 print문을 통해 바로 출력.\n",
    "\n",
    "\n",
    "\n",
    "4. 평가 단계\n",
    "with torch.no_grad(): 평가 단계에서는 기울기 계산이 필요 없으므로 메모리와 연산을 절약.\n",
    "\n",
    "for images, labels in test_loader: 테스트 데이터를 배치 단위로 반복.\n",
    "\n",
    "images, labels = images.to(device), labels.to(device): 데이터를 device로 이동.\n",
    "\n",
    "test_output = model(images): 모델에 입력해 예측 결과를 얻는다.\n",
    "\n",
    "test_loss = loss_function(test_output,labels): 예측값과 정답을 비교해 손실을 계산.\n",
    "\n",
    "epoch_test_loss += test_loss.item()/ len(test_loader): 배치 손실을 전체 배치 개수로 나눠 누적(평균 손실).\n",
    "\n",
    "acc = ((test_output.argmax(dim=1) == labels).float().mean()): 배치 정확도 계산.\n",
    "\n",
    "epoch_test_accuracy += acc.item()/ len(test_loader): 배치 정확도를 전체 배치 개수로 나눠 누적(평균 정확도).\n",
    "\n",
    "test_losses.append(epoch_test_loss), test_accuracy.append(epoch_test_accuracy): 한 에폭이 끝나면 평균 테스트 손실과 정확도를 리스트에 저장.\n",
    "\n",
    "+) 각 에폭의 학습 및 테스트 손실/정확도를 print문을 통해 바로 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1682491219105,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "gpW1PIReOg2c",
    "outputId": "ea22bdca-1cc0-4eef-b419-9bc960464941"
   },
   "outputs": [],
   "source": [
    "#plot the loss function\n",
    "plt.title(\"Train and Test Loss\")\n",
    "plt.plot(range(n_epochs),train_losses, label=\"train\")\n",
    "plt.plot(range(n_epochs),test_losses, label=\"test\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.title(\"Train and Test Loss\"): 그래프의 제목을 \"Train and Test Loss\"로 설정.\n",
    "\n",
    "plt.plot(range(n_epochs),train_losses, label=\"train\"): x축을 에폭 번호(0부터 9), y축을 학습 손실(train_losses 리스트의 값)로 하여 학습 손실 곡선을 그림. label=\"train\"은 범례에 표시될 이름.\n",
    "\n",
    "plt.plot(range(n_epochs),test_losses, label=\"test\"): x축을 에폭 번호, y축을 테스트 손실(test_losses 리스트의 값)로 하여 테스트 손실 곡선을 그림. label=\"test\"는 범례에 표시될 이름.\n",
    "\n",
    "plt.xlabel('Epoch'): x축의 레이블을 'Epoch'로 설정.\n",
    "\n",
    "plt.ylabel('Loss'): y축의 레이블을 'Loss'로 설정.\n",
    "\n",
    "plt.legend(): 그래프에 범례를 표시.\n",
    "\n",
    "plt.show(): 생성된 그래프를 화면에 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1682491222870,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "vs86Tm5hOJ4m",
    "outputId": "39424491-657b-4f4a-b876-c54566012abd"
   },
   "outputs": [],
   "source": [
    "#plot the accuracy function\n",
    "plt.title(\"Train and Test accuracy\")\n",
    "plt.plot(range(n_epochs),train_accuracy, label=\"train\")\n",
    "plt.plot(range(n_epochs),test_accuracy, label=\"test\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.title(\"Train and Test accuracy\"): 그래프의 제목을 \"Train and Test accuracy\"로 설정.\n",
    "\n",
    "plt.plot(range(n_epochs),train_accuracy, label=\"train\"): x축을 에폭 번호, y축을 학습 정확도(train_accuracy 리스트의 값)로 하여 학습 정확도 곡선을 그림.\n",
    "\n",
    "plt.plot(range(n_epochs),test_accuracy, label=\"test\"): x축을 에폭 번호, y축을 테스트 정확도(test_accuracy 리스트의 값)로 하여 테스트 정확도 곡선을 그림.\n",
    "\n",
    "plt.xlabel('Epoch'): x축의 레이블을 'Epoch'로 설정.\n",
    "\n",
    "plt.ylabel('Accuracy'): y축의 레이블을 'Accuracy'로 설정. \n",
    "\n",
    "plt.legend(): 그래프에 범례를 표시.\n",
    "\n",
    "plt.show(): 생성된 그래프를 화면에 출력."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHUQovX0PTxS"
   },
   "source": [
    "개미-벌 데이터 영상 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1682491227380,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "wQsdSH9bPTMV",
    "outputId": "cf5418f8-218b-435e-978b-d9eaea1c7094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개미-벌 분류를 위한 라이브러리 임포트 및 장치 설정\n",
    "from torchvision.datasets import ImageFolder: 이미지 파일이 클래스별로 정리된 디렉토리에서 데이터셋을 쉽게 로드할 수 있는 ImageFolder 클래스를 명시적으로 임포트."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1682491230818,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "H9BbRgbpPlHu"
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.Resize((224,224))\n",
    "                                       ,transforms.ToTensor()\n",
    "                                       ,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 데이터에 적용할 일련의 변환을 transforms.Compose를 사용하여 정의.\n",
    "\n",
    "transforms.Resize((224,224)): 입력 이미지의 크기를 224x224 픽셀로 조절. 이는 많은 사전 훈련된 CNN 모델(예: ResNet, VGG)의 표준 입력 크기.\n",
    "\n",
    "transforms.ToTensor(): PIL 이미지나 NumPy 배열을 PyTorch 텐서로 변환하고, 픽셀 값의 범위를 [0, 1]로 정규화.\n",
    "\n",
    "transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]): 이미지의 각 채널(RGB)을 주어진 평균(mean)과 표준편차(std)를 사용하여 정규화합니다. 이 값들은 ImageNet 데이터셋의 통계치로, ImageNet으로 사전 훈련된 모델을 사용할 때 일반적으로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22397,
     "status": "ok",
     "timestamp": 1682493897242,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "Kczt9tOtS8Ic",
    "outputId": "b4dc39a4-ac37-4dd9-a96c-6eeffa7661ae"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Colaboratory 환경에서 사용자의 Google Drive를 /content/gdrive/ 경로에 마운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1682494334532,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "yw9QDIvrehfi",
    "outputId": "47ab69ad-2caa-48d1-e0c5-e79285dc0266"
   },
   "outputs": [],
   "source": [
    "cd /content/gdrive/MyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colab의 현재 작업 디렉토리를 마운트된 Google Drive 내의 'MyDrive' 디렉토리로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2427,
     "status": "ok",
     "timestamp": 1682494339581,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "uyB2W91dPp9n"
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder('./hymenoptera_data/train/',transform =data_transform)\n",
    "valid_dataset = ImageFolder('./hymenoptera_data/val/',transform =data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageFolder 클래스를 사용하여 개미와 벌 이미지 데이터셋을 로드.\n",
    "    train_dataset = ImageFolder('./hymenoptera_data/train/', transform=data_transform): ./hymenoptera_data/train/ 경로에 있는 학습용 이미지 데이터셋을 로드. ImageFolder는 이 경로 아래에 있는 하위 디렉토리(예: 'ants', 'bees')를 클래스 레이블로 자동 인식. data_transform에 정의된 변환이 각 이미지에 적용.\n",
    "    \n",
    "    valid_dataset = ImageFolder('./hymenoptera_data/val/', transform=data_transform): ./hymenoptera_data/val/ 경로에 있는 검증용(validation) 이미지 데이터셋을 로드하며, 동일한 변환을 적용.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1682494355341,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "I2_M4ENsPsrC",
    "outputId": "cd73e987-ba0e-461b-d532-8e5397440952"
   },
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(valid_dataset))\n",
    "print(train_dataset[0][0].size())\n",
    "print(valid_dataset[0][0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(len(train_dataset)): 학습 데이터셋의 총 이미지 수를 출력.\n",
    "\n",
    "print(len(valid_dataset)): 검증 데이터셋의 총 이미지 수를 출력.\n",
    "\n",
    "print(train_dataset[0][0].size()): 학습 데이터셋의 첫 번째 이미지 텐서의 크기를 출력. Resize((224,224))와 ToTensor() 변환으로 인해 (3, 224, 224) 형태 (채널, 높이, 너비)가 된다.\n",
    "\n",
    "print(valid_dataset[0][0].size()): 검증 데이터셋의 첫 번째 이미지 텐서의 크기를 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1682494360068,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "e0uiXopSQCX1",
    "outputId": "4aa9a05a-eba4-469b-c49c-946cabb41bc6"
   },
   "outputs": [],
   "source": [
    "class_names = train_dataset.classes\n",
    "class_names_to_idx = train_dataset.class_to_idx\n",
    "print(class_names)\n",
    "print(class_names_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_names = train_dataset.classes: ImageFolder로 로드된 학습 데이터셋의 클래스 이름들을 리스트 형태로 가져옴 (예: ['ants', 'bees']).\n",
    "\n",
    "class_names_to_idx = train_dataset.class_to_idx: 클래스 이름과 해당 클래스의 정수 인덱스를 매핑하는 딕셔너리를 가져옴 (예: {'ants': 0, 'bees': 1}).\n",
    "\n",
    "print(class_names): 클래스 이름 리스트를 출력.\n",
    "\n",
    "print(class_names_to_idx): 클래스 이름-인덱스 매핑 딕셔셔너리를 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1682494363895,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "YrFQh585QF_F",
    "outputId": "6a223ebd-3f28-4f55-fbbc-a7357183f818"
   },
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터셋(train_dataset)의 첫 번째 샘플을 출력. 이는 (변환된 이미지 텐서, 해당 이미지의 레이블 인덱스) 형태의 튜플."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1682494367003,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "ShnrOdT-QJVq",
    "outputId": "4356d3b0-514f-4649-da7d-064c16d4217c"
   },
   "outputs": [],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터셋의 첫 번째 샘플에서 이미지 텐서(train_dataset[0][0])의 내용을 출력. Normalize 변환으로 인해 픽셀 값들이 특정 범위로 정규화되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1682494371906,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "XeQleU1iQLBe"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4,num_workers=0,shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=4,num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개미-벌 이미지 데이터셋을 위한 학습 및 검증 데이터 로더를 생성.\n",
    "    batch_size=4: 배치 크기를 4로 설정합니다.\n",
    "    \n",
    "    num_workers=0: 데이터 로딩에 사용할 서브프로세스의 수입니다. 0은 메인 프로세스에서 데이터를 로드함을 의미합니다.\n",
    "    \n",
    "    shuffle=True (train_loader): 학습 데이터는 에폭마다 섞습니다.\n",
    "    \n",
    "    shuffle=False (valid_loader, 기본값): 검증 데이터는 섞지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1682494426838,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "eBODDFIIQPPh",
    "outputId": "e67743b3-d495-4d8c-cf8f-635c14ec0947"
   },
   "outputs": [],
   "source": [
    "print(len(train_loader)) #244/4\n",
    "print(len(valid_loader)) #153/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(len(train_loader)): 학습 데이터 로더가 한 에폭당 생성하는 배치의 수를 출력. 주석 #244/4는 (총 학습 샘플 수 / 배치 크기)를 의미.\n",
    "\n",
    "print(len(valid_loader)): 검증 데이터 로더가 생성하는 배치의 수를 출력. 주석 #153/4는 (총 검증 샘플 수 / 배치 크기)를 의미. (153/4 = 38.25이므로, 39개의 배치가 생성될 것이며 마지막 배치는 더 작을 수 있다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "executionInfo": {
     "elapsed": 2633,
     "status": "ok",
     "timestamp": 1682494446095,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "64OfnVvMQSdP",
    "outputId": "bfcfb1f6-c505-4386-da06-5c72a28067b7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "#    print(img.shape)\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "#    print(\"max: {}, min: {}\".format(np.max(img), np.min(img)))\n",
    "    plt.imshow(img)\n",
    "#    print(img.shape)\n",
    "\n",
    "imshow(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 시각화를 위한 imshow 함수를 다시 정의. 이번에는 컬러 이미지(3채널)를 처리하고, 셀 59에서 정의한 Normalize 변환을 되돌리는(역정규화) 과정을 포함.\n",
    "\n",
    "    img = img.numpy().transpose((1, 2, 0)): PyTorch 텐서(C,H,W)를 NumPy 배열(H,W,C)로 변환.\n",
    "    \n",
    "    mean = np.array(...), std = np.array(...): 정규화 시 사용했던 평균과 표준편차 값을 정의.\n",
    "    \n",
    "    img = std * img + mean: 역정규화 연산 (input * std) + mean을 수행하여 픽셀 값을 원래 범위에 가깝게 복원.\n",
    "    \n",
    "    img = np.clip(img, 0, 1): 부동소수점 연산으로 인해 값이 [0, 1] 범위를 약간 벗어날 수 있으므로, 이 범위로 값을 제한(클리핑).\n",
    "\n",
    "imshow(train_dataset[0][0]): 학습 데이터셋의 첫 번째 이미지를 이 함수를 사용하여 화면에 표시."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "executionInfo": {
     "elapsed": 2885,
     "status": "ok",
     "timestamp": 1682494452373,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "cnRczBO7QpaP",
    "outputId": "c3cefff0-3c87-44df-84dc-7e450bf1c9c7"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "# Get a batch of training data\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "# Make a grid from batch\n",
    "img_grid = utils.make_grid(images)\n",
    "imshow(img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 라이브러리 임포트\n",
    "torchvision 패키지에서 데이터 전처리(transform)와 유틸리티 함수(utils)를 불러옴.\n",
    "utils에는 이미지 그리드 생성 함수인 make_grid가 포함.\n",
    "\n",
    "2. 배치 데이터 한 묶음 가져오기\n",
    "train_loader는 DataLoader 객체로, 학습 데이터셋을 배치 단위로 반환.\n",
    "iter(train_loader)로 이터레이터를 만들고, next()로 첫 번째 배치(이미지와 레이블)를 받아옴.\n",
    "\n",
    "\n",
    "3. 배치 텐서 크기 확인\n",
    "이미지 텐서와 레이블 텐서의 shape을 출력.\n",
    "\n",
    "images의 shape은 [batch_size, channels, height, width] -> 4장의 224*224 RGB 이미지.\n",
    "labels는 각 이미지의 정답 클래스 인덱스가 담긴 1차원 텐서.\n",
    "\n",
    "4. 이미지 그리드 생성\n",
    "make_grid 함수는 여러 이미지를 한 장의 그리드 이미지로 합쳐주기.\n",
    "\n",
    "입력은 4차원 텐서(배치)여야 하며, 기본적으로 한 행에 8개씩 배치(nrow=8, 이미지가 8개 미만이면 한 행에 모두 표시).\n",
    "\n",
    "반환값은 [channels, height, width] 형태의 3차원 텐서로, 합쳐진 그리드 이미지.\n",
    "\n",
    "5. 그리드 이미지 시각화\n",
    "imshow 함수는 텐서 이미지를 matplotlib로 시각화.\n",
    "\n",
    "imshow 내부동작을 통해 numpy 배열화 후 역정규화 실행.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1682494457607,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "mvu7tGjTQtWD"
   },
   "outputs": [],
   "source": [
    "#CNN 모델 생성\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size=(5, 5), stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size=(5, 5), stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=(3, 3), padding=1)\n",
    "        self.fc1 = nn.Linear(in_features= 64 * 6 * 6, out_features=500)\n",
    "        self.fc2 = nn.Linear(in_features=500, out_features=50)\n",
    "        self.fc3 = nn.Linear(in_features=50, out_features=2)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = F.max_pool2d(X, 2)\n",
    "        \n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = F.max_pool2d(X, 2)\n",
    "        \n",
    "        X = F.relu(self.conv3(X))\n",
    "        X = F.max_pool2d(X, 2)\n",
    "        \n",
    "#         print(X.shape)\n",
    "        X = X.view(X.shape[0], -1)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CNN 모델 생성: 주석으로, 개미-벌 이미지 분류를 위한 새로운 CNN 모델을 정의하는 부분임을 명시.\n",
    "\n",
    "class CNN(nn.Module):: nn.Module을 상속받는 CNN 클래스를 정의.\n",
    "\n",
    "__init__(self): 모델의 계층들을 초기화.\n",
    "\n",
    "    self.conv1 = nn.Conv2d(in_channels = 3, ...): 첫 번째 합성곱 계층. 입력 채널이 3(컬러 이미지)으로 변경. 출력 채널 16, 5x5 커널, 스트라이드 2, 패딩 1.\n",
    "    \n",
    "    self.conv2 = nn.Conv2d(in_channels = 16, ...): 두 번째 합성곱 계층. 입력 채널 16, 출력 채널 32.\n",
    "    \n",
    "    self.conv3 = nn.Conv2d(in_channels = 32, ...): 세 번째 합성곱 계층. 입력 채널 32, 출력 채널 64, 3x3 커널.\n",
    "    \n",
    "    self.fc1 = nn.Linear(in_features= 64 * 6 * 6, ...): 첫 번째 완전 연결 계층. 입력 특징 수는 이전 합성곱 및 풀링 계층을 거친 후의 특징 맵 크기(6x6)와 채널 수(64)를 곱한 값(2304). 출력 특징 수는 500.\n",
    "    \n",
    "    self.fc2 = nn.Linear(in_features=500, out_features=50): 두 번째 완전 연결 계층.\n",
    "    \n",
    "    self.fc3 = nn.Linear(in_features=50, out_features=2): 세 번째 완전 연결 계층 (출력 계층). 출력 특징 수가 2로, 개미(ant)와 벌(bee) 두 개의 클래스를 분류.\n",
    "\n",
    "forward(self, X): 모델의 순전파 과정을 정의합.\n",
    "\n",
    "    X = F.relu(self.conv1(X)), X = F.max_pool2d(X, 2): 각 합성곱 계층 뒤에는 ReLU 활성화 함수와 2x2 맥스 풀링이 적용.\n",
    "    \n",
    "    # print(X.shape): 주석 처리된 코드로, 평탄화 전 특징 맵의 크기를 확인하는 데 사용할 수 있다.\n",
    "    \n",
    "    X = X.view(X.shape[0], -1): 다차원 특징 맵을 완전 연결 계층에 입력하기 위해 1차원 벡터로 평탄화.\n",
    "    \n",
    "    X = F.relu(self.fc1(X)), X = F.relu(self.fc2(X)): 완전 연결 계층 뒤에도 ReLU 활성화 함수가 적용.\n",
    "    \n",
    "    X = self.fc3(X): 마지막 출력 계층. 일반적으로 분류 문제에서는 이 출력에 Softmax 함수를 적용하지만, nn.CrossEntropyLoss를 손실 함수로 사용하면 내부적으로 Softmax가 처리되므로 여기서는 별도의 활성화 함수를 적용하지 않는다.\n",
    "    \n",
    "    return X: 모델의 최종 예측값(각 클래스에 대한 점수)을 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1682494460564,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "iHS-tTIEQxg_",
    "outputId": "e2adf8c5-786c-4d69-e400-d6158b675c55"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "model = CNN().to(device)  \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.manual_seed(1): 난수 시드를 고정.\n",
    "\n",
    "model = CNN().to(device): 위에서 정의한 CNN 클래스의 인스턴스(모델 객체)를 생성하고, device로 옮기기.\n",
    "\n",
    "model: 모델의 구조를 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1682494463229,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "nyt_4_z0QzSy"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적화 알고리즘으로 SGD(Stochastic Gradient Descent)를 사용. 학습률은 0.001, 모멘텀(momentum) 값은 0.9로 설정. 모멘텀은 이전 기울기의 방향을 현재 업데이트에 반영하여 수렴 속도를 높이고 지역 최적점(local minima)을 벗어나는 데 도움을 줄 수 있다.\n",
    "loss_function = nn.CrossEntropyLoss(): 손실 함수로 교차 엔트로피 손실을 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225961,
     "status": "ok",
     "timestamp": 1682494738475,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "SJ5rH5ZBQ4zH",
    "outputId": "87f7e106-0621-41cc-cfc8-7fa12646a3a7"
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "train_accuracy=[]\n",
    "valid_accuracy=[]\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    for images, labels in train_loader:\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)    \n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step()         \n",
    "               \n",
    "        epoch_loss += loss.item()/len(train_loader)\n",
    "        acc = ((outputs.argmax(dim=1) == labels).float().mean())\n",
    "        epoch_accuracy += acc.item()/len(train_loader)\n",
    "    train_losses.append(epoch_loss)  \n",
    "    train_accuracy.append(epoch_accuracy)  \n",
    "    print('Epoch : {}, train loss : {:.5f}, train accuracy : {:.5f}'.format(epoch+1, epoch_loss, epoch_accuracy))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        epoch_valid_accuracy=0\n",
    "        epoch_valid_loss =0\n",
    "        for images, labels in valid_loader:          \n",
    "            images=images.to(device)\n",
    "            labels=labels.to(device)    \n",
    "            valid_outputs = model(images)\n",
    "            valid_loss = loss_function(valid_outputs, labels)\n",
    "            \n",
    "            epoch_valid_loss += valid_loss.item()/ len(valid_loader)\n",
    "            acc = ((valid_outputs.argmax(dim=1) == labels).float().mean())\n",
    "            epoch_valid_accuracy += acc.item()/ len(valid_loader)\n",
    "        valid_losses.append(epoch_valid_loss) \n",
    "        valid_accuracy.append(epoch_valid_accuracy)  \n",
    "        print('Epoch : {}, test loss : {:.5f}, test accuracy : {:.5f}'.format(epoch+1, epoch_test_loss, epoch_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 변수 초기화\n",
    "\n",
    "이 셀은 모델을 10 에폭 동안 학습시키면서, 각 에폭이 끝날 때마다 학습 데이터셋과 검증 데이터셋에 대한 평균 손실 및 정확도를 계산하여 각각의 리스트(train_losses, valid_losses, train_accuracy, valid_accuracy)에 저장.\n",
    "\n",
    "2. 에폭 루프: 전체 학습 n_epochs만큼 반복.\n",
    "\n",
    "- epoch_loss, epoch_accuracy: 한 에폭 동안의 누적 손실과 정확도를 저장할 변수\n",
    "\n",
    "\n",
    "3. 학습 단계:\n",
    "   \n",
    "for images, labels in train_loader: 학습 데이터 전체를 배치 단위로 반복.\n",
    "\n",
    "images, labels = images.to(device), labels.to(device): 데이터를 GPU 또는 CPU로 이동.\n",
    "\n",
    "outputs = model(images): 모델에 이미지를 입력해 예측 결과(로짓)를 얻는다.\n",
    "\n",
    "loss = loss_function(outputs, labels): 예측 결과와 실제 정답 레이블을 비교하여 손실값을 계산.\n",
    "\n",
    "optimizer.zero_grad(): 이전 배치에서 계산된 기울기(gradient)를 초기화.\n",
    "\n",
    "loss.backward(): 손실을 모델 파라미터에 대해 역전파(backpropagation)하여 기울기를 계산.\n",
    "\n",
    "optimizer.step(): 계산된 기울기를 이용해 모델 파라미터를 업데이트.\n",
    "\n",
    "epoch_loss += loss.item()/len(train_loader): 현재 배치의 손실값을 전체 배치 개수로 나눠 누적(평균 손실 계산).\n",
    "\n",
    "acc = ((outputs.argmax(dim=1) == labels).float().mean()): 각 배치에서 예측값과 정답이 일치하는 비율(정확도)을 계산.\n",
    "\n",
    "epoch_accuracy += acc.item()/len(train_loader): 배치별 정확도를 전체 배치 개수로 나눠 누적(평균 정확도 계산).\n",
    "\n",
    "- loss.item()과 acc.item(): 텐서에서 스칼라 값을 추출하여 누적 합계에 사용합니다. 이렇게 해야 메모리 누수를 방지하고 정확한 평균값을 계산할 수 있다.\n",
    "\n",
    "train_losses.append(epoch_loss), train_accuracy.append(epoch_accuracy): 한 에폭이 끝나면 평균 손실과 정확도를 리스트에 저장.\n",
    "\n",
    "+) 각 에폭의 학습 및 테스트 손실/정확도를 print문을 통해 바로 출력.\n",
    "\n",
    "\n",
    "\n",
    "4. 평가 단계\n",
    "with torch.no_grad(): 평가 단계에서는 기울기 계산이 필요 없으므로 메모리와 연산을 절약.\n",
    "\n",
    "for images, labels in valid_loader: 검증 데이터를 배치 단위로 반복.\n",
    "\n",
    "images, labels = images.to(device), labels.to(device): 데이터를 device로 이동.\n",
    "\n",
    "valid_output = model(images): 모델에 입력해 예측 결과를 얻는다.\n",
    "\n",
    "valid_loss = loss_function(valid_output,labels): 예측값과 정답을 비교해 손실을 계산.\n",
    "\n",
    "epoch_valid_loss += valid_loss.item()/ len(valid_loader): 배치 손실을 전체 배치 개수로 나눠 누적(평균 손실).\n",
    "\n",
    "acc = ((valid_output.argmax(dim=1) == labels).float().mean()): 배치 정확도 계산.\n",
    "\n",
    "epoch_valid_accuracy += acc.item()/ len(valid_loader): 배치 정확도를 전체 배치 개수로 나눠 누적(평균 정확도).\n",
    "\n",
    "valid_losses.append(epoch_valid_loss), valid_accuracy.append(epoch_valid_accuracy): 한 에폭이 끝나면 평균 테스트 손실과 정확도를 리스트에 저장.\n",
    "\n",
    "+) 각 에폭의 학습 및 테스트 손실/정확도를 print문을 통해 바로 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 1679,
     "status": "ok",
     "timestamp": 1682494765305,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "q93nucxeRAFy",
    "outputId": "eafdbfb3-29f0-4c7a-875d-0cb7a4a7e57d"
   },
   "outputs": [],
   "source": [
    "#plot the loss function\n",
    "plt.title(\"Train and Valid Loss\")\n",
    "plt.plot(range(n_epochs),train_losses, label=\"train\")\n",
    "plt.plot(range(n_epochs),valid_losses, label=\"valid\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.title(\"Train and Valid Loss\"): 그래프의 제목을 \"Train and Valid Loss\"로 설정.\n",
    "\n",
    "plt.plot(range(n_epochs),train_losses, label=\"train\"): x축을 에폭 번호(0부터 9), y축을 학습 손실(train_losses 리스트의 값)로 하여 학습 손실 곡선을 그림. label=\"train\"은 범례에 표시될 이름.\n",
    "\n",
    "plt.plot(range(n_epochs),valid_losses, label=\"valid\"): x축을 에폭 번호, y축을 검증 손실(valid_losses 리스트의 값)로 하여 테스트 손실 곡선을 그림. label=\"test\"는 범례에 표시될 이름.\n",
    "\n",
    "plt.xlabel('Epoch'): x축의 레이블을 'Epoch'로 설정.\n",
    "\n",
    "plt.ylabel('Loss'): y축의 레이블을 'Loss'로 설정.\n",
    "\n",
    "plt.legend(): 그래프에 범례를 표시.\n",
    "\n",
    "plt.show(): 생성된 그래프를 화면에 출력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "executionInfo": {
     "elapsed": 1021,
     "status": "ok",
     "timestamp": 1682494769051,
     "user": {
      "displayName": "최승훈",
      "userId": "10545016366834953850"
     },
     "user_tz": -540
    },
    "id": "hD3qVySLRA79",
    "outputId": "ccaa0d59-5507-4fc9-8b46-389702841f5b"
   },
   "outputs": [],
   "source": [
    "#plot the accuracy function\n",
    "plt.title(\"Train and Valid accuracy\")\n",
    "plt.plot(range(n_epochs),train_accuracy, label=\"train\")\n",
    "plt.plot(range(n_epochs),valid_accuracy, label=\"valid\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.title(\"Train and Valid accuracy\"): 그래프의 제목을 \"Train and Valid accuracy\"로 설정.\n",
    "\n",
    "plt.plot(range(n_epochs),train_accuracy, label=\"train\"): x축을 에폭 번호, y축을 학습 정확도(train_accuracy 리스트의 값)로 하여 학습 정확도 곡선을 그림.\n",
    "\n",
    "plt.plot(range(n_epochs),valid_accuracy, label=\"valid\"): x축을 에폭 번호, y축을 검증 정확도(test_accuracy 리스트의 값)로 하여 테스트 정확도 곡선을 그림.\n",
    "\n",
    "plt.xlabel('Epoch'): x축의 레이블을 'Epoch'로 설정.\n",
    "\n",
    "plt.ylabel('Accuracy'): y축의 레이블을 'Accuracy'로 설정. \n",
    "\n",
    "plt.legend(): 그래프에 범례를 표시.\n",
    "\n",
    "plt.show(): 생성된 그래프를 화면에 출력."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP9ZQC0qLeNux4FEaVYnMc5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
